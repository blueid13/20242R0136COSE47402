{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install datasets --quiet\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# 데이터셋 경로 설정\n",
        "data_path = '/content/drive/MyDrive/Colab Notebooks/COSE474/MVSA/data/'  # 이미지 및 텍스트 파일 폴더\n",
        "\n",
        "# 텍스트 전처리 함수\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # 소문자로 변환\n",
        "    text = ''.join(e for e in text if e.isalnum() or e.isspace())  # 특수문자 제거\n",
        "    return text\n",
        "\n",
        "# 커스텀 데이터셋 클래스 정의\n",
        "class ImageTextDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "\n",
        "        # 폴더 내 파일 목록 가져오기\n",
        "        file_names = [f.split('.')[0] for f in os.listdir(folder_path) if f.endswith('.jpg')]  # .jpg 파일 기준\n",
        "        unique_ids = set(file_names)  # 중복 제거\n",
        "\n",
        "        for file_id in unique_ids:\n",
        "            # 이미지와 텍스트 파일 경로 생성\n",
        "            image_file = os.path.join(folder_path, f\"{file_id}.jpg\")\n",
        "            text_file = os.path.join(folder_path, f\"{file_id}.txt\")\n",
        "\n",
        "            # 이미지와 텍스트 파일이 모두 있는 경우 로드\n",
        "            if os.path.exists(image_file) and os.path.exists(text_file):\n",
        "                self.data.append((image_file, text_file))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_file, text_file = self.data[idx]\n",
        "\n",
        "        # 이미지 로드 및 전처리\n",
        "        image = cv2.imread(image_file)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"이미지를 로드할 수 없습니다: {image_file}\")\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # RGB로 변환\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        else:\n",
        "            # 기본 변환 적용\n",
        "            image = cv2.resize(image, (224, 224))\n",
        "            image = image / 255.0  # 정규화\n",
        "            image = torch.tensor(image, dtype=torch.float32)\n",
        "            image = image.permute(2, 0, 1)  # (H, W, C) -> (C, H, W)\n",
        "\n",
        "        # 텍스트 로드 및 전처리\n",
        "        with open(text_file, 'r') as file:\n",
        "            raw_text = file.read().strip()\n",
        "        text = preprocess_text(raw_text)\n",
        "\n",
        "        return image, text\n",
        "\n",
        "# 데이터셋 및 데이터로더 생성\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = ImageTextDataset(data_path, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmFBTZ5dJqdV",
        "outputId": "b85bb277-83b7-4a2c-8ccd-da971c8169f9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "ZCQHOIcmJucu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 모델과 라벨 1차 평가"
      ],
      "metadata": {
        "id": "Z6eZtH_BVGde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# 1. 라벨 파일 로드 및 전처리\n",
        "label_file_path = '/content/drive/MyDrive/Colab Notebooks/COSE474/MVSA/label.txt'\n",
        "\n",
        "# 라벨 파일 로드\n",
        "label_df = pd.read_csv(label_file_path, sep='\\t', header=0)\n",
        "\n",
        "# 컬럼 이름 지정 (필요에 따라)\n",
        "label_df.columns = ['ID', 'Annotator1', 'Annotator2', 'Annotator3']\n",
        "\n",
        "# 감성 라벨 매핑\n",
        "label_mapping = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
        "\n",
        "# 다수결 라벨 계산 함수\n",
        "def get_majority_label(labels):\n",
        "    label_counts = Counter(labels)\n",
        "    majority_label = label_counts.most_common(1)[0][0]\n",
        "    return majority_label\n",
        "\n",
        "# 각 샘플에 대한 다수결 라벨 계산\n",
        "majority_labels = []\n",
        "sample_ids = label_df['ID'].tolist()\n",
        "for idx, row in label_df.iterrows():\n",
        "    labels = []\n",
        "    for annotator in ['Annotator1', 'Annotator2', 'Annotator3']:\n",
        "        text_label = row[annotator].split(',')[0].strip()  # 텍스트 라벨 추출\n",
        "        labels.append(text_label)\n",
        "    # 라벨 매핑 적용\n",
        "    mapped_labels = [label_mapping[label] for label in labels]\n",
        "    # 다수결 라벨 계산\n",
        "    majority_label = get_majority_label(mapped_labels)\n",
        "    majority_labels.append(majority_label)"
      ],
      "metadata": {
        "id": "W9no3qj9P3-8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 데이터 경로 설정 및 최적화\n",
        "# Google Drive에서 로컬 디스크로 데이터 복사 (한 번만 실행)\n",
        "local_data_path = '/content/data/'\n",
        "if not os.path.exists(local_data_path):\n",
        "    !cp -r '/content/drive/MyDrive/Colab Notebooks/COSE474/MVSA/data/' '/content/data/'\n",
        "\n",
        "data_path = local_data_path  # 로컬 디스크 경로로 변경"
      ],
      "metadata": {
        "id": "kBrrbZGnTlAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 로드\n",
        "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"  # 예시 모델 이름\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# GPU 사용 설정 (가능한 경우)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval()  # 평가 모드로 설정"
      ],
      "metadata": {
        "id": "B8-un5HMTpfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 데이터셋 및 데이터로더 구현\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, text_files):\n",
        "        self.text_files = text_files\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text_file = self.text_files[idx]\n",
        "        with open(text_file, 'r', encoding='utf-8') as file:\n",
        "            raw_text = file.read().strip()\n",
        "        return raw_text\n",
        "\n",
        "# 유효한 텍스트 파일 리스트 생성\n",
        "text_files = []\n",
        "valid_sample_ids = []\n",
        "for sample_id in sample_ids:\n",
        "    text_filename = f\"{sample_id}.txt\"\n",
        "    text_file = os.path.join(data_path, text_filename)\n",
        "    if os.path.exists(text_file):\n",
        "        text_files.append(text_file)\n",
        "        valid_sample_ids.append(sample_id)\n",
        "    else:\n",
        "        print(f\"{text_filename} 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "# 데이터셋 및 데이터로더 생성\n",
        "text_dataset = TextDataset(text_files)\n",
        "batch_size = 32  # 배치 크기 설정\n",
        "text_dataloader = DataLoader(text_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "nEPt6JEhTro7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 예측 수행\n",
        "predicted_labels = []\n",
        "all_majority_labels = []\n",
        "total_batches = len(text_dataloader)\n",
        "print(f\"총 배치 수: {total_batches}\")\n",
        "\n",
        "for batch_idx, batch_texts in enumerate(text_dataloader):\n",
        "    # 진행 상황 출력\n",
        "    if batch_idx % 10 == 0:\n",
        "        print(f\"{batch_idx}/{total_batches} 배치 처리 중...\")\n",
        "\n",
        "    # 텍스트 토크나이즈\n",
        "    inputs = tokenizer(\n",
        "        list(batch_texts),\n",
        "        return_tensors='pt',\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
        "\n",
        "    # 모델 예측\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        predicted_labels.extend(preds)\n"
      ],
      "metadata": {
        "id": "TVKcBrQATtps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 라벨 정렬\n",
        "# valid_sample_ids에 대응하는 majority_labels 추출\n",
        "valid_indices = [sample_ids.index(sid) for sid in valid_sample_ids]\n",
        "filtered_majority_labels = [majority_labels[i] for i in valid_indices]\n",
        "\n",
        "# 7. 예측과 라벨 비교\n",
        "# 정확도 계산\n",
        "correct = sum([1 for pred, true in zip(predicted_labels, filtered_majority_labels) if pred == true])\n",
        "accuracy = correct / len(predicted_labels)\n",
        "print(f\"모델의 정확도: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(classification_report(filtered_majority_labels, predicted_labels, target_names=['Negative', 'Neutral', 'Positive']))\n"
      ],
      "metadata": {
        "id": "Q5tbs27QTv6d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}